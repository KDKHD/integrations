{
  "attributes": {
    "raw": {
      "document": "---\ntitle: \"Ingesting threat data with the Threat Intel Filebeat module\"\nslug: \"ingesting-threat-data-with-the-threat-intel-filebeat-module\"\ndate: \"2023-03-01\"\ndescription: \"Tutorial that walks through setting up Filebeat to push threat intelligence feeds into your Elastic Stack.\"\nauthor:\n  - slug: andrew-pease\n  - slug: marius-iversen\nimage: \"photo-edited-12-t.jpg\"\ncategory:\n  - slug: security-operations\n  - slug: detection-science\ntags:\n  - tutorial\n  - filebeat\n  - threat intel\n---\n\nThe ability for security teams to integrate threat data into their operations substantially helps their organization identify potentially malicious endpoint and network events using indicators identified by other threat research teams. In this blog, we’ll cover how to ingest threat data with the Threat Intel Filebeat module. In future blog posts, we’ll cover enriching threat data with the Threat ECS fieldset and operationalizing threat data with Elastic Security.\n\n## Elastic Filebeat modules\n\nElastic Filebeat modules simplify the collection, parsing, and visualization of data stored in common log formats. Elastic publishes a variety of [Filebeat modules](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-modules.html) that are focused on collecting the data you want for use within Elasticsearch. These modules provide a standardized and “turnkey” method to ingest specific data sources into the Elastic Stack.\n\nUsing these capabilities, the Threat Intel Filebeat module:\n\n- Consumes threat data from six open source feeds\n- Loads threat data into Elasticsearch\n- Normalizes threat data into the [Threat ECS fieldset](https://www.elastic.co/guide/en/ecs/current/ecs-threat.html)\n- Enables threat analysis through dashboards and visualizations\n\nAnalysts and threat hunters can use this data for raw threat hunting, enrichment, intelligence analysis and production, and detection logic.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/overview.jpg\n\nThe six feeds included with the 7.13 Filebeat Threat Intel module are as follows (additional feeds may be added in the future):\n\n- [Abuse.ch Malware](https://urlhaus-api.abuse.ch/v1/payloads/recent)\n- [Abuse.ch URL](https://urlhaus.abuse.ch/)\n- [AlienVault Open Threat Exchange (OTX)](https://otx.alienvault.com/)\n- [Anomali Limo](https://www.anomali.com/resources/limo)\n- [Malware Bazaar](https://bazaar.abuse.ch/)\n- [Malware Information Sharing Platform (MISP)](https://www.misp-project.org/)\n\nUsing the Threat Intel Filebeat module, you can choose from several open source threat feeds, store the data in Elasticsearch, and leverage the Kibana Security App to aid in security operations and intelligence analysis.\n\n## Threat Intel Filebeat module\n\nGenerally, the Filebeat Threat Intel module can be started without any configuration to collect logs from Abuse.ch feeds, Anomali Limo, and Malware Bazaar. However, the optional AlienVault OTX and MISP datasets require tokens to authenticate to their feed sources. Thankfully, obtaining a token is a simple process.\n\n### AlienVault OTX\n\nThe team over at Alien Labs® has created the Open Threat Exchange (OTX)® as an open threat intelligence community. This environment provides access to a diverse community of researchers and practitioners. OTX allows anyone in the community to discuss, research, validate, and share threat data. Additionally, OTX has an Application Programming Interface (API) endpoint that provides a read-only feed; which is how the Filebeat module consumes the OTX threat data.\n\nTo access the OTX API, you simply need to [create an account](https://otx.alienvault.com/). Once you have an account, you can subscribe to specific OTX community reports and threat data feeds called “Pulses.” These Pulses are retrieved by the Filebeat module and stored in Elasticsearch.\n\nPulses are updated at various cadences, but many are daily or even hourly. The Pulse has a summary of the threat, indicators, and various other enrichments that can help you contextually assess the threat in your environment.\n\nTo subscribe to Pulses, select Browse → Pulses, and then subscribe to any Pulses that you’d like. You can sort by the most recently modified to identify the most active Pulses.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/av-pulse.jpg)\n\nNow that you’ve subscribed to Pulses of interest, we’ll need to collect your API key.\n\n### Retrieving Your API Key\n\nThe API key is used to securely authenticate to OTX and obtain the indicators from Pulses.\n\nTo retrieve your API key, select your userID → Settings, and then copy your OTX Key.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/av-api.jpg)\n\nNow that we have your OTX Key, let’s set up MISP.\n\n## MISP\n\nThe Malware Information Sharing Platform (MISP) is an open source project for collecting, storing, distributing, and sharing indicators about threats.\n\nWhile MISP is extremely powerful and has a tremendous variety of features, it can be a bit cumbersome to set up. If you are planning on setting up MISP for production, check out the [official documentation](https://github.com/MISP/MISP/tree/2.4/docs) for installing MISP on Kali, RHEL (incl. CentOS and Fedora), or Ubuntu.\n\nIf your organization doesn’t have a MISP instance, you can use one of the many projects that use Docker to get MISP up and running. There’s a [great and maintained project](https://github.com/coolacid/docker-misp) by Jason Kendall (@coolacid) that is about as turnkey as you could ask for.\n\n### Standing up CoolAcid’s MISP Docker Containers\n\nAs a caveat, this will cover a default development deployment of MISP. It should not be used in production. Please see the [official MISP documentation](https://github.com/MISP/MISP/tree/2.4/docs) for properly deploying a secure MISP instance.\n\nAs a few prerequisites, you’ll need to have Docker Compose and Git installed:\n\n- **Docker Compose** is used to automate the deployment and configuration of the containers. You can check out [Docker’s documentation](https://docs.docker.com/compose/install/) on getting Compose installed.\n- **Git** is a version-control framework used to coordinate software development throughout contributors and community members. You can check out the [Git documentation](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) on getting Git installed.\n\nNext, we need to clone CoolAcid’s repository and fire up the containers.\n\n- git clone: Copies the remote repository to your local machine into a file called “docker-misp”\n- cd docker-misp: Changes into the “docker-misp” directory\n- docker-compose up -d: Uses the docker-compose file in the “docker-misp” directory to download, build, and start all of the relevant containers in “detached mode” (in the background)\n\n```\nCode Block 1 - Starting MISP Containers\n\n$ git clone https://github.com/coolacid/docker-misp.git\n$ cd docker-misp\n$ docker-compose up -d\n\nPulling misp (coolacid/misp-docker:core-latest)...\ncore-latest: Pulling from coolacid/misp-docker\na54cbf64e415: Pull complete\n84e78d2508ee: Pull complete\n433476aac54e: Pull complete\n780a2dfa04f6: Pull complete\nDigest: sha256:7f380ad0d858bdec2c4e220f612d80431b1a0b0cb591311ade38da53b50a4cc1\nStatus: Downloaded newer image for coolacid/misp-docker:core-latest\nPulling misp-modules (coolacid/misp-docker:modules-latest)...\nmodules-latest: Pulling from coolacid/misp-docker\ncdd040608d7b: Pull complete\n4e340668f524: Pull complete\na4501f203bb2: Downloading [=========================================>         ]  166.1MB/201.3MB\n2cdaa3afcfca: Download complete\n99a18a4e84d6: Downloading [=============================>                     ]  130.8MB/218.3MB\n...\n\n```\n\nOnce all of the containers are started, simply browse to [https://localhost](https://localhost:8080) and log in with the default credentials of admin@admin.test and a passphrase of admin. You will immediately be required to change your passphrase.\n\n### Configuring default MISP feeds\n\nOnce you have started the MISP containers and changed your default credentials, hover over Sync Actions and then select List Feeds.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/misp-listfeeds.jpg)\n\nHighlight the available feeds, select “Enable selected” to enable the default feeds, and then “Fetch and store all feed data.”\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/misp-enablefeeds.jpg)\n\nNext, select on the “Event Actions” menu item, select “List Events” and you’ll see data begin to be populated. This will take a while.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/misp-listevents.jpg)\n\nWhile the data provided by the MISP threat feeds is being downloaded, let’s get your API key.\n\n### Collecting Your API Key\n\nTo collect your API key, select “Administration” and then “List Users.” You will see your account. Next to your “Authkey” will be an eye icon, select it to show your API key and copy that down.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/misp-api.jpg)\n\nNow that we have set up and configured MISP and retrieved our API key, we can configure the actual Filebeat module.\n\n## Installing Filebeat\n\nGetting the Threat Intel module is no different than any other Filebeat module. Check out the [Quick Start guide to install Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation-configuration.html) either as a standalone binary or a package for macOS, Windows, or Linux.\n\n## Configuring the Threat Intel Filebeat module\n\nOnce you have Filebeat, we’ll simply enable the module (ensure filebeat is in your $PATH).\n\n```\nCode Block 2 - Enabling the Threat Intel Filebeat Module\n\nfilebeat modules enable threatintel\n```\n\nNext, let’s configure feeds. We’ll do this by modifying the module configuration files. Depending on your OS and installation method, the configuration files will be located in different locations:\n\nWindows\n\n- C:\\Program Files\\Filebeat\\modules.d\\threatintel.yml\n- If installed with [Chocolatey](https://community.chocolatey.org/packages/filebeat)\n- C:\\ProgramData\\chocolatey\\lib\\filebeat\\tools\\modules.d\\threatintel.yml\n\nmacOS\n\n- filebeat/modules.d/threatintel.yml\n- If installed with [Homebrew](https://formulae.brew.sh/formula/filebeat)\n- /usr/local/etc/filebeat/modules.d/threatintel.yml\n\nLinux\n\n- filebeat/modules.d/threatintel.yml\n- If Installed with [APT](https://www.elastic.co/guide/en/beats/filebeat/current/setup-repositories.html#_apt) or [YUM / dnf](https://www.elastic.co/guide/en/beats/filebeat/current/setup-repositories.html#_yum)\n- /etc/filebeat/modules.d/threatintel.yml\n\nUsing whichever text editor you’re most comfortable with, open threatintel.yml and we’ll add your OTX API key, your MISP API key, and validate Anomali’s credential pair.\n\n### Abuse URL feed configuration\n\nBy default, the Abuse URL feed is enabled and does not need modification. The feed includes domain, URI, and URL indicators with additional context for significant dates, tags, submitter, status, etc.\n\n```\nCode Block 3 - Configuring the Abuse URL Feed\n\nabuseurl:\n  enabled: true\n\n  # Input used for ingesting threat intel data.\n  var.input: httpjson\n\n  # The URL used for Threat Intel API calls.\n  var.url: https://urlhaus-api.abuse.ch/v1/urls/recent/\n\n  # The interval to poll the API for updates.\n  var.interval: 10m\n```\n\n#### Abuse malware feed configuration\n\nBy default, the Abuse malware feed is enabled and does not need modification. The feed includes file hashes and hosts with additional context for significant dates, tags, status, etc.\n\n```\nCode Block 4 - Configuring the Abuse Malware Feed\n\nabusemalware:\n    enabled: true\n\n    # Input used for ingesting threat intel data.\n    var.input: httpjson\n\n    # The URL used for Threat Intel API calls.\n    var.url: https://urlhaus-api.abuse.ch/v1/payloads/recent/\n\n    # The interval to poll the API for updates.\n    var.interval: 10m\n```\n\n### MISP feed configuration\n\nBy default, the MISP feed is enabled but requires configuration. The feed includes various file and network data with additional context for significant dates, tags, status, submitter, etc.\n\nThe API endpoint that Filebeat will query needs to be configured. If you are running MISP on the same system as Filebeat, you can use var.url: https://localhost/event/restSearch. If you are running MISP elsewhere, you’ll need to enter that hostname or IP address in lieu of localhost.\n\nThe API token is the “Authkey” that you retrieved during the previous MISP setup steps. You’ll enter that as the value for var.api_token:\n\nIf you are using a self-signed SSL certificate for MISP, you’ll want to disable the SSL verification mode by uncommenting the var.ssl.verification_mode: none line.\n\n```\nCode Block 5 - Configuring the MISP Feed\n\nmisp:\n    enabled: true\n\n    # Input used for ingesting threat intel data, defaults to JSON.\n    var.input: httpjson\n\n    # The URL of the MISP instance, should end with \"/events/restSearch\".\n    var.url: https://localhost/events/restSearch\n\n    # The authentication token used to contact the MISP API. Found when looking at user account in the MISP UI.\n    var.api_token: MISP-Authkey\n\n    # Configures the type of SSL verification done, if MISP is running on self signed certificates\n    # then the certificate would either need to be trusted, or verification_mode set to none.\n    var.ssl.verification_mode: none\n\n    # Optional filters that can be applied to the API for filtering out results. This should support the majority of\n    # fields in a MISP context. For examples please reference the filebeat module documentation.\n    #var.filters:\n    #  - threat_level: [4, 5]\n    #  - to_ids: true\n\n    # How far back to look once the beat starts up for the first time, the value has to be in hours. Each request\n    # afterwards will filter on any event newer than the last event that was already ingested.\n    var.first_interval: 300h\n\n    # The interval to poll the API for updates.\n    var.interval: 5m\n```\n\n### AlienVault OTX feed configuration\n\nBy default, the AlienVault OTX feed is enabled but requires configuration. The feed includes various file and network data with additional context for significant dates, tags, etc.\n\nThe API token is the “OTX Key” that you retrieved during the AlienVault OTX setup steps. You’ll enter that as the value for var.api_token:\n\n```\nCode Block 6 - Configuring the AlienVault OTX Feed\n\notx:\n  enabled: true\n\n  # Input used for ingesting threat intel data\n  var.input: httpjson\n\n  # The URL used for OTX Threat Intel API calls.\n  var.url: https://otx.alienvault.com/api/v1/indicators/export\n\n  # The authentication token used to contact the OTX API, can be found on the OTX UI.\n  Var.api_token: OTX-Key\n\n  # Optional filters that can be applied to retrieve only specific indicators.\n  #var.types: \"domain,IPv4,hostname,url,FileHash-SHA256\"\n\n  # The timeout of the HTTP client connecting to the OTX API\n  #var.http_client_timeout: 120s\n\n  # How many hours to look back for each request, should be close to the configured interval.\n  # Deduplication of events is handled by the module.\n  var.lookback_range: 1h\n\n  # How far back to look once the beat starts up for the first time, the value has to be in hours.\n  var.first_interval: 400h\n\n  # The interval to poll the API for updates\n  var.interval: 5m\n```\n\n### Anomali feed configuration\n\nBy default, the Anomali feed is enabled but requires configuration. The feed includes various file and network data with additional context for significant dates, tags, etc.\n\nThe default username and passphrase for the Limo feed is guest:guest, but are commented out. If you do not have other credential pairs, you can simply uncomment var.username and var.password.\n\nAt the time of this writing, Anomali has 11 collections that they provide as part of their Limo feed. The var.url variable is where the collection is defined. To get a list of the collections, you can query the Anomali Limo collections API endpoint (while not required, [jq](https://stedolan.github.io/jq/download/) makes the collections easier to read).\n\n```\nCode Block 7 - Configuring the Anomali Limo Collections\n\n$ curl -L -u guest:guest https://limo.anomali.com/api/v1/taxii2/feeds/collections | jq\n\n{\n  \"collections\": [\n    {\n      \"can_read\": true,\n      \"can_write\": false,\n      \"description\": \"\",\n      \"id\": \"107\",\n      \"title\": \"Phish Tank\"\n    },\n    {\n      \"can_read\": true,\n      \"can_write\": false,\n      \"description\": \"\",\n      \"id\": \"135\",\n      \"title\": \"Abuse.ch Ransomware IPs\"\n    },\n    {\n      \"can_read\": true,\n      \"can_write\": false,\n      \"description\": \"\",\n      \"id\": \"136\",\n      \"title\": \"Abuse.ch Ransomware Domains\"\n    },\n...\n```\n\nThe collection ID can be inserted into the Anomali configuration. There are a few ways to do this. You can:\n\n- Manually change the ID\n- Enter all of the IDs and comment out all but the collection you’re wanting to target\n- Create a duplicate Anomali configuration section for each collection\n\nThe below example shows the approach of duplicate sections for each collection; notice the different collection ID for each section (31, 313, 33) in the var.url: field.\n\n```\nCode Block 8 - Configuring the Anomali Limo Feed\n\n  anomali:\n    enabled: true\n\n    # Input used for ingesting threat intel data\n    var.input: httpjson\n\n    # The URL used for Threat Intel API calls. Limo has multiple different possibilities for URL's depending\n    # on the type of threat intel source that is needed.\n    var.url: https://limo.anomali.com/api/v1/taxii2/feeds/collections/31/objects\n\n    # The Username used by anomali Limo, defaults to guest.\n    var.username: guest\n\n    # The password used by anomali Limo, defaults to guest.\n    var.password: guest\n\n    # How far back to look once the beat starts up for the first time, the value has to be in hours.\n    var.first_interval: 400h\n\n    # The interval to poll the API for updates\n    var.interval: 5m\n\n  anomali:\n    enabled: true\n\n    # Input used for ingesting threat intel data\n    var.input: httpjson\n\n    # The URL used for Threat Intel API calls. Limo has multiple different possibilities for URL's depending\n    # on the type of threat intel source that is needed.\n    var.url: https://limo.anomali.com/api/v1/taxii2/feeds/collections/313/objects\n\n    # The Username used by anomali Limo, defaults to guest.\n    var.username: guest\n\n    # The password used by anomali Limo, defaults to guest.\n    var.password: guest\n\n    # How far back to look once the beat starts up for the first time, the value has to be in hours.\n    var.first_interval: 400h\n\n    # The interval to poll the API for updates\n    var.interval: 5m\n\n  anomali:\n    enabled: true\n\n    # Input used for ingesting threat intel data\n    var.input: httpjson\n\n    # The URL used for Threat Intel API calls. Limo has multiple different possibilities for URL's depending\n    # on the type of threat intel source that is needed.\n    var.url: https://limo.anomali.com/api/v1/taxii2/feeds/collections/33/objects\n...\n\n```\n\nNow that we’ve configured the module to consume threat feed data, let’s send the data into Elasticsearch and visualize it with Kibana.\n\n## Setting up Elasticsearch and Kibana\n\nThe Filebeat Threat Intel module will send the configured threat feed data into Elasticsearch, which can be visualized with Kibana. Please see the Elastic documentation for setting up [Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/setup.html) and [Kibana](https://www.elastic.co/guide/en/kibana/current/setup.html) production environments. Additionally, if you’re looking for a turnkey approach, you can quickly and securely set up an [Elastic Cloud](https://cloud.elastic.co) account.\n\nFor this non-production example, we’ll be using one of the many projects that use Docker to get Elasticsearch and Kibana up and running quickly.\n\n### Standing up an Elasticsearch and Kibana container\n\nAs a caveat, this will cover a convenient default development deployment of Elasticsearch and Kibana. It should not be used in production. Please see the [Elastic documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-stack-security.html) for properly deploying a secure instance.\n\nWe’ll simply collect the repository and start the Docker containers.\n\n- git clone: This copies the remote repository to your local machine into a folder called “elastic-container”\n- cd elastic-container: Changes into the “elastic-container” directory\n- sh elastic-container.sh start: This downloads and starts the Elasticsearch and Kibana containers\n\n```\nCode Block 9 - Starting Elastic Containers\n\n$ git clone https://github.com/peasead/elastic-container.git\n$ cd elastic-container\n$ sh elastic-container.sh start\n\n7.12.1: Pulling from elasticsearch/elasticsearch\nddf49b9115d7: Already exists\n4df4d6995ad2: Pull complete\ne180ce5d1430: Pull complete\nb3801a448e4f: Downloading [====>                      ]  199.3MB/353.1MB\na3100bfb487c: Download complete\n817ce7c869c7: Download complete\n485f138f2280: Download complete\n\n7.12.1: Pulling from kibana/kibana\nddf49b9115d7: Already exists\n588c50b1b6af: Extracting [====================>       ]  34.93MB/40.52MB\n9d32826b6fa0: Download complete\n01017880c9d9: Download complete\nefcedd43b7be: Download complete\n0887ad2a14e0: Download complete\n625b277c1f7b: Downloading [=====>                     ]  52.27MB/320.4MB\n68815bc8856d: Download complete\ne9e0d8f8fa8c: Download complete\n```\n\nCheck out the repository [documentation](https://github.com/peasead/elastic-container) for additional usage and configuration options (if needed).\n\nOnce all of the containers are started, simply browse to [http://localhost:5601](https://localhost:5601) and log in with the default credentials of elastic and a passphrase of password.\n\n## Consuming threat data with Filebeat\n\nThere are multiple [output options for Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/configuring-output.html), so use whatever is easiest for you. We’ll use a local Elasticsearch instance in this example. Using a local instance of Elasticsearch and Kibana requires no modification to the filebeat.yml file.\n\nTo validate our configuration, let’s first test our configuration and access to Elasticsearch.\n\n- filebeat test config: This will test to ensure your filebeat.yml configuration is correct (if you modified it to fit your environment)\n- filebeat test output - this will test to ensure you can access Elasticsearch\n\n```\nCode Block 10 - Testing Filebeat Configuration and Connection\n\n$ filebeat test config\nConfig OK\n\n$ filebeat test output\nelasticsearch: http://localhost:9200...\n  parse url... OK\n  connection...\n    parse host... OK\n    dns lookup... OK\n    addresses: ::1, 127.0.0.1\n    dial up... OK\n  TLS... WARN secure connection disabled\n  talk to server... OK\n  version: 7.12.0\n```\n\nTo load the dashboards, index pattern, and ingest pipelines, let’s run the setup.\n\n- filebeat setup: This will connect to Kibana and load the index pattern, ingest pipelines, and the saved objects (tags, visualizations, and dashboards)\n\n```\nCode Block 11 - Setting Up Filebeat Index Patterns and saved objects in Kibana\n\n$ filebeat setup\n\nOverwriting ILM policy is disabled. Set `setup.ilm.overwrite: true` for enabling.\n\nIndex setup finished.\nLoading dashboards (Kibana must be running and reachable)\nLoaded dashboards\nSetting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.\nSee more: https://www.elastic.co/guide/en/machine-learning/current/index.html\nLoaded machine learning job configurations\nLoaded Ingest pipelines\n\n```\n\nFinally, let’s [start Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-starting.html) to begin collecting!\n\nNext, browse to Kibana and select the Dashboards app. To make the dashboards easier to find, they all use the “threat intel” tag.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/filebeat-dashboards.jpg)\n\nThere is a dashboard for each feed and an overview dashboard that shows the health of the module.\n\n![](/assets/images/ingesting-threat-data-with-the-threat-intel-filebeat-module/overview.jpg\n\nIt may take several minutes for all of the data to be retrieved as the different sources are polled.\n\n## What’s next?\n\nWe’re working on converting the existing visualizations into [Lens](https://www.elastic.co/kibana/kibana-lens) and adding [drilldown](https://www.elastic.co/guide/en/kibana/current/drilldowns.html) capabilities to each visualization.\n\nAdditionally, as we mentioned in the beginning of this post, this is part one of a three-part series on operationalizing threat data in the Elastic Stack. The next post will cover enhancements to the Threat ECS fieldset and enriching threat data using local endpoint and network observations.\n\nWe’re working on adding additional open source and commercial feeds. If you have feeds that you’d like to see prioritized, please check out the contribution section below.\n\nFinally, we’re looking at opportunities to add context and enrichments to observed events with third-party sources.\n\nSo stay tuned — we’re continuing to lean hard into empowering our customers to defend their environments. Being able to action threat data is a key part of that journey.\n\n## How can you contribute?\n\nThe [Threat Intel Filebeat module](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-module-threatintel.html) was released with Elastic 7.12, which means that it is still in beta. Testing the feeds, configurations, visualizations, etc. is strongly encouraged. We love hearing feedback.\n\nIn addition to the Threat Intel module, there are some other repositories that are related to the collection, processing, and analysis of TI data:\n\n- The Beats [repository](https://github.com/elastic/beats), where you can contribute to, and enhance, threat data feeds\n- The Elastic Common Schema (ECS) [repository](https://github.com/elastic/ecs), where you can be a part of the discussion on shaping how threat data is described in the Elastic Stack\n- The Kibana [repository](https://github.com/elastic/kibana), where analysts interact with the data stored in Elasticsearch\n- The Detection Rules [repository](https://github.com/elastic/detection-rules), where detection logic and rules are created and stored\n\nThe best way to contribute to the community is to explore the functionality, features, and [documentation](https://www.elastic.co/guide/en/beats/filebeat/7.12/filebeat-module-threatintel.html) and let us know through a [Github Issue](https://github.com/elastic/beats/issues/new/choose) if there is a problem or something you’d like to see.\n\nIf you’re new to Elastic, experience our latest version of the [Elasticsearch Service](https://www.elastic.co/elasticsearch/service) on Elastic Cloud. Also be sure to take advantage of our [Quick Start training](https://www.elastic.co/training/elastic-security-quick-start) to set yourself up for success.\n"
    },
    "title": "Ingesting threat data with the Threat Intel Filebeat module",
    "slug": "ingesting-threat-data-with-the-threat-intel-filebeat-module",
    "date": "2023-03-01",
    "description": "Tutorial that walks through setting up Filebeat to push threat intelligence feeds into your Elastic Stack.",
    "author": [
      {
        "slug": "andrew-pease"
      },
      {
        "slug": "marius-iversen"
      }
    ],
    "image": "photo-edited-12-t.jpg",
    "category": [
      {
        "slug": "security-operations"
      },
      {
        "slug": "detection-science"
      }
    ],
    "tags": [
      "tutorial",
      "filebeat",
      "threat intel"
    ]
  },
  "id": "security_labs_content-ingesting_threat_data_with_the_threat_intel_filebeat_module-md",
  "type": "security_labs_content"
}
